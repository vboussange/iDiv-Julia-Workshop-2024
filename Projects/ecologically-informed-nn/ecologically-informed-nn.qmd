---
title: "Ecologically-informed neural networks"
jupyter: julia-1.10
execute: 
    eval: false
    cache: true
    warning: false
showsol: false
format:
    html:
        toc: true
        toc-depth: 4
        # toc-expand: 2
editor:
  render-on-save: true
---

![](https://files.ipbes.net/ipbes-web-prod-public-files/styles/xl_1920_scale/azblob/2023-09/IAS%20website%20image.png.webp?itok=tVaiqu2q)

Invasive species pose major threats on nature, nature’s contributions to people, and good quality of life ([IPBES, 2019](https://zenodo.org/records/3553579)), with global annual costs estimated to exceed 423 billion USD. 
The management of invasive alien species requires the modelling of the species range and spread dynamics, in order to optimally allocate control effort.
While current state-of-the-art modelling approaches such as deep learning species distribution model (deep SDM) can help in determining the potential niche of invasive alien species (e.g., [Brun et al. 2024](https://www.nature.com/articles/s41467-024-48559-9)), they assume that species are always in equilibrium with their environment, neglecting key transient ecological processes such as demographic changes and dispersal. This oversight is problematic, because these processes are crucial in determining the establishment of a species in a novel environment.

The proposed project aims to fill this gap by developing an ecologically-informed neural network, following a physics-informed neural network approach (see e.g.[Raissi et al. 2019](https://www.nature.com/articles/s41467-024-48559-9)). 

![](https://benmoseley.blog/wp-content/uploads/2021/08/pinn-1536x608.png)

Specifically, we will build a process-based dynamical model, that we will couple to a deep SDM. The resulting approach will allow to inform the process-based model with presence-absence data, generating a data-driven dynamical forecast of species invasion. 

Julia is great for physics-informed approaches, because it allows to quickly build fast process-based models. Because Julia is an AD-pervasive language, these process-based models can be further differentiated, so that you could eventually calibrate its parameters against the ecological data at hand. 


## What you will learn
- Building a simple deep SDM
- Building a simple process-based model
- Scientific machine learning

## Prerequisite
- [Read this tutorial to understand what is a physics-informed neural network and how to code it in Julia](https://book.sciml.ai/notes/03-Introduction_to_Scientific_Machine_Learning_through_Physics-Informed_Neural_Networks/)

## Data
You'll work with a mock-up presence-absence (PA) dataset of a virtual invasive species. But feel free to work with real data if you have an idea! This PA dataset is derived from a true abundance dataset, generated by a process-based model.

### Presence absence data
![](data/PA.gif)
in `data/PA_data.csv`

Notice how the number of samples increases over time. You should correct for this bias!

### True population abundance data
![](data/anim.gif)
in `data/true_abundance_data.jld2`

You may use this dataset to evaluate your model, but not for training!


### Environmental raster data
![](data/bio1.png)
in `data/bio1.tif`

## Work packages

The different work packages below can be addressed independently and distributed among different teams. The team could collaborate on a public repository.

### **WP A**: Process-based model
The goal is to construct a model which simulates the dynamics of species abundance on a landscape. Given a landscape consisting of $P$ patches $\{p_1, \dots, p_P \}$, we want to model the dynamics of the population abundance vector ${\bf n}_{t} = (n_{1, t}, \dots, n_{P, t})$ where $n_{i, t}$ corresponds to the population density on $p_i$.

We will assume that the population experiences a logistic growth, and that it is subject to dispersal. We will use a difference equation model to express these processes

$$
n_{i, t+1} = n_{i, t} + \mathcal{E}(n_{i, t}) + [\mathcal{D}({\bf n_t})]_i, 
$$

where $\mathcal{E}$ coresponds to the ecological dynamics, 
$$
\mathcal{E}(n_{i, t}) = n_{i, t}(1 - \frac{n_{i, t}}{K_i})
$$
with $K_i$ the carrying capacity on patch $p_i$, and where
$\mathcal{D}$ is the dispersal kernel
$$
[\mathcal{D}({\bf n_t})]_i = \left[ \sum_j  u_{j, t} m_{j, i} - \sum_j  u_{i, t} m_{i, j}\right]
$$

with  $m_{j,i}$ the proportion of individuals migrating from $p_j$ to $p_i$. The first term corresponds to incoming individuals, the second to leaving individuals. 

#### Ecology
We will assume that 
$$
K_{i} = e^{-\kappa(T_i - T^\star)^2}
$$
where $T_i$ is the temperature on patch $p_i$, $T^\star$ is the optimal temperature for the species, and $\kappa$ defines how the carrying capacity decreases under sub-optimal conditions.

#### Dispersal
We will assume that 
$$
m_{i,j} = \begin{cases} 
m \, e^{-d_{i,j}/\alpha}, & \text{if } i \neq j \\
0, & \text{if } i = j 
\end{cases}
$$
where $m$ is the migration rate and $d_{i,j}$ is the distance between $p_i$ and $p_j$.


::: {.callout-warning icon="false"}
# Your task

Implement this model! For this, you'll need to create a `DynSDM` struct. This struct should be used with the `simulate` function:


```julia
model = DynSDM(...)
simulate(model, u0, ntsteps)
```

Given a `model` and an initial abundance vector `u0` and the number of time steps `ntsteps`, this function returns a vector of size `ntsteps` containing abundance vectors with the same shape as `u0`  for each of the time steps investigated.

You are given a `utils.jl` file, which contains helper functions to aid your work. Important functions are detailed in the boxes below.
:::

#### Hints

::: {.callout-tip collapse="true"}
#### Loading the data 

You will use temperature data from CHELSA. Run the following snippet. It will download the `bio1` raster from CHELSA, and load it.

```{julia}
include("project_src/utils.jl")

temp = load_raster()

plot(temp)
```
:::

::: {.callout-tip collapse="true"}
# Defining the landscape
The `utils.jl` file provides you with a `Landscape` struct. This struct is very useful, because it calculates the distance between all pixels of a raster. Use it in your model!

Here is a snippet of how you can use it:


```{julia}
landscape = Landscape(temp)
landscape.dists
```
Here, `landscape.dists[i, j]` corresponds to the `d_{i,j}` coefficient, i.e. the distance between pixel `i` and `j`.


The method `get_raster_values` allows you to transform a flat vector into a raster corresponding to the associated landscape. 

For illustration purposes, here we plot the distance of all patch to the 400th patch in the landscape:

```{julia}
distances_to_400 = get_raster_values(landscape.dists[400,:], landscape)
plot(distances_to_400)
```
:::

::: {.callout-tip collapse="true"}
# Numerical values

```{julia}
T0 = 4. # optimal growth temperature
κ = 1.
α = 4. # mean dispersal distance
```
:::


::: {.callout-tip collapse="true"}
# Initial conditions

We suggest using the following initial conditions:

```{julia}
x = lookup(temp, X)
y = lookup(temp, Y)
x_0 = x[floor(Int, length(x)/2)]
y_0 = y[floor(Int, length(y)/2)]
a = 2.
b = 1.
u0_raster = @. exp(- a * ((x - x_0)^2 + (y-y_0)^2)) * exp(- b * (temp - T0)^2)
plot(u0_raster)
```
:::


::: {.callout-tip collapse="true"}
# Defining state variables

It will be easier to handle a flat vector for calculating the dynamics.

```{julia}
u0 = u0_raster[:]
```

But you can use the following helper to transform `u0` or any state variable vector into a raster

```{julia}
plot(get_raster_values(u0, landscape))
```
:::

::: {.callout-tip collapse="true"}
# Dispersal kernel

Implementing the dispersal kernel is not trivial - you need to do it write to get performance. Consider using the following implementation:

```{julia}

disp_proximities = sparse(disp_kern.(landscape.dists)) # we transform the distances in proximities
D = - m * (I - (disp_proximities ./ sum(disp_proximities,dims=1)))
```
Now you need to convince yourself that `D * u` exactly equals $\mathcal{D}({\bf n}_t)$. 
:::

::: {.callout-tip collapse="true"}
# `DynSDM` specs

You probably want to define a structure of the sort 

```julia
Base.@kwdef struct DynSDM{LD,KK,DD} <: AbstractDynModel
    landscape::LD
    K::KK
    D:DD
end
```

that can be instantiated with a function 
```julia
build_dyn_model(landscape::Landscape)
```

This structure will ensure easy access to `K` and `D`, while storing the landscape so that you can project flat state variable vectors to a raster.

:::

<!-- 
You could consider any sort of model, but here are some examples
- The discrete reaction diffusion model from [Bonneau et al. 2017](https://esajournals.onlinelibrary.wiley.com/doi/10.1002/ecs2.1979), where individuals experience a logistic growth with a locally defined carrying capacity $K_i$ that depends on the landscape characteristics, and where some individuals disperse to neighboring vertices.
- The metapopulation model from [Hanski et al. 2003](https://www.nature.com/articles/35008063)  -->


### **WP B**: Constructing a deep SDM in Julia

::: {.callout-warning}
# Your task
The goal is to construct a deep SDM which can predict the species distribution at time $t$, given an array of absence-presence observations. 

You are given an array `XY_arr` where `XY_arr[i] = (pred, target)`, where `pred[:,i]` is an array of predictors to predict `target[i]`, which is `1` if the species has been detected and `0` if not. Specifically, `pred[:,i] = (x, y, temp)`.

Build a model (with Flux.jl) that predicts the full species distribution for each time steps.

To do so, build a function 
```julia
train(;nns, 
        PA_data, 
        optim, 
        n_epochs,)
```
where `nns` is an array of neural network, with `nns[i](pred)` predicting the distribution of the species at time $t_i$.
:::

::: {.callout-tip collapse="true"}
# Absence presence data

:::

::: {.callout-tip collapse="true"}
# Loss function

:::

::: {.callout-tip collapse="true"}
# Neural network architecture

:::


##### **Sub-objective**: Hyperparameter optimisation

Hyperparameters of a neural network model are parameters that are not learned during training but are set by the user before training. The hyperparameters define the structure and behavior of the neural network and influence how the model learns from the input data. 
Some resources:
- [Hyperopt.jl](https://github.com/baggepinnen/Hyperopt.jl).

- [A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning](https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)


#### **WP C**: Ecologically-informed neural network
The objective is to constrain the deep SDM developed in **B** with the process-based model developed in **A**.

Specifically, you should additionaly constrain the deep SDM so that its predictions are coherent with the process-based model. That is, we eventually want that

`simulate(model, nns[i-1](pred), 1) ≈ nns[i](pred)`

while `nns` still predict the PA data. To do so, build a function 
```julia
train(;nns, 
        dyn_model, 
        PA_data, 
        optim, 
        n_epochs,)
```

to perform training.


Once this is done, check how good are your predictions outside the training range by predicting with

```julia
simulate(model, f[end](pred), 1)
```

which will predict ${\bf n}_{T+1}$.


