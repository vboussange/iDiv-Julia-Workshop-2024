{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallel and Distributed Computing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multithreading vs Multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "- **Multithreading**: multiple threads with shared memory are executed concurrently; each thread runs a process.\n",
    "\n",
    "- **Multiprocessing**: multiple processors are executed concurrently; each processor can run one or more threads, each thread runs a process.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*hZ3guTdmDMXevFiT5Z3VrA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multithreading in Julia\n",
    "ðŸ¤¯ built-in support with the `Threads` standard library ðŸ¤¯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 2.0, 8.0, 8.0, 3.0, 5.0, 7.0, 6.0, 4.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "\n",
    "Threads.@threads for i = 1:10\n",
    "    a[i] = Threads.threadid()\n",
    "end\n",
    "println(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "The number of execution threads is controlled either by using the `-t`/`--threads` command line argument \n",
    "\n",
    "```shell\n",
    "julia --threads 10 my_script.jl\n",
    "```\n",
    "\n",
    "or by using the `JULIA_NUM_THREADS` environment variable. This can also be changed in VSCode setting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- `-t`/`--threads` takes precedence.\n",
    "\n",
    "- The number of threads can either be specified as an integer (`--threads=4`) or as auto (`--threads=auto`) (number of local CPU threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "To check the number of threads available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is another example to make sure that `Threads.@threads` does indeed run code in parrallel: we compare a simple loop against a loop using `Threads.@threads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10.020 s (249 allocations: 6.89 KiB)\n"
     ]
    }
   ],
   "source": [
    "myfun() = sleep(1)\n",
    "function myfun_loop()\n",
    "    for i = 1:10\n",
    "        myfun()\n",
    "    end\n",
    "end\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime myfun_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.007 s (123 allocations: 6.42 KiB)\n"
     ]
    }
   ],
   "source": [
    "function myfun_loop_multithreading()\n",
    "    Threads.@threads for i = 1:10\n",
    "        myfun()\n",
    "    end\n",
    "end\n",
    "\n",
    "@btime myfun_loop_multithreading()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Be careful with race condition!\n",
    "Multiple processes or threads accessing and manipulating shared resources or data concurrently may lead to unexpected and undesirable results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: println(length(a)) == 1000",
     "output_type": "error",
     "traceback": [
      "AssertionError: println(length(a)) == 1000\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Academia/Postdoc_S2z/teaching/iDiv_Julia_workshop/materials/Day2/13_parallel_computing/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X13sZmlsZQ==.jl:5"
     ]
    }
   ],
   "source": [
    "a = Float64[]\n",
    "Threads.@threads for i in 1:1000\n",
    "    push!(a, i)\n",
    "end\n",
    "@assert println(length(a)) == 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### `lock` \n",
    "\n",
    "The `lock` function can be used to prevent race condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "lk = ReentrantLock()\n",
    "Threads.@threads for i in 1:100\n",
    "    x = i^2\n",
    "    lock(lk) do\n",
    "        push!(a, x)\n",
    "    end\n",
    "end\n",
    "println(length(a)) # ==1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `lk` is a synchronisation primitive\n",
    "- ensures that only one thread can access the shared resource at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overhead\n",
    "- There's a performance benefit to parallelization, but the overhead for starting threads may be an overkill. \n",
    "- For multithreading to be worth, you need a reasonably large amount of \"real work\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "N = 2^10\n",
    "x = fill(1.0f0, N)  # a vector filled with 1.0 (Float32)\n",
    "y = fill(2.0f0, N);  # a vector filled with 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  69.744 ns (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "function sequential_add!(y, x)\n",
    "    for i in eachindex(y, x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime sequential_add!($y, $x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.333 Î¼s (41 allocations: 4.23 KiB)\n"
     ]
    }
   ],
   "source": [
    "function parallel_add!(y, x)\n",
    "    Threads.@threads for i in eachindex(y, x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@btime parallel_add!($y, $x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practical use of multithreading: grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simul (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function simul(noise, batch_size)\n",
    "    # do something with noise and batch_size\n",
    "    sleep(1)\n",
    "    return randn()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- we may want to evaluate it for many combinations of `noise` and `batch_size`. \n",
    "- Let's do so by creating a dictionary `pars` for each combination of arguments, and adding it to an array `pars_arr`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pars_arr = Dict[]\n",
    "\n",
    "noises = [0.1, 0.2, 0.3]\n",
    "batch_sizes = [1000, 2000, 3000]\n",
    "\n",
    "for noise in noises, batch_size in batch_sizes\n",
    "    pars = Dict()\n",
    "    pars[\"noise\"] = noise\n",
    "    pars[\"batch_size\"] = batch_size\n",
    "    push!(pars_arr, pars)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll also create a `DataFrame` to store the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>0Ã—3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Result</th><th style = \"text-align: left;\">noise</th><th style = \"text-align: left;\">batch_size</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Result & noise & batch\\_size\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m0Ã—3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m Result \u001b[0m\u001b[1m noise \u001b[0m\u001b[1m batch_size \u001b[0m\n",
       "     â”‚\u001b[90m Any    \u001b[0m\u001b[90m Any   \u001b[0m\u001b[90m Any        \u001b[0m\n",
       "â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using DataFrames\n",
    "df_results = DataFrame(\"Result\" => [],\n",
    "                    \"noise\" => [],\n",
    "                    \"batch_size\" => [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And now, we can write the loop. Let's be fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:02 ( 0.33  s/it)\u001b[39m\u001b[K\n"
     ]
    }
   ],
   "source": [
    "using ProgressMeter\n",
    "progr = Progress(length(pars_arr), showspeed = true, barlen = 10)\n",
    "\n",
    "loc = Threads.ReentrantLock()\n",
    "\n",
    "Threads.@threads for k in 1:length(pars_arr)\n",
    "    p = pars_arr[k]\n",
    "    noise = p[\"noise\"]\n",
    "    batch_size = p[\"batch_size\"]\n",
    "    try\n",
    "        out = simul(noise, batch_size)\n",
    "        lock(loc) do\n",
    "            push!(df_results, (out, noise, batch_size));\n",
    "        end\n",
    "    catch e\n",
    "        println(\"problem with p = $(pars_arr[k])\")\n",
    "        println(e)\n",
    "    end\n",
    "    next!(progr)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Atomic operations\n",
    "Atomic operations can also be used to prevent race condition, see the [dedicated section](https://docs.julialang.org/en/v1/manual/multi-threading/#Atomic-Operations) in Julia documentation. Atomic operations are limited to primitive types, but can be faster than locks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-processing in Julia\n",
    "\n",
    "built-in support with the `Distributed` standard library. \n",
    "\n",
    "- More difficult to deploy than mulitthreading. \n",
    "- useful when you have a lot of work that cannot be split among multiple threads and needs to be distributed across multiple machines (e.g., Monte Carlo simulations).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `julia -p 4` provides `4` worker processes on the local machine. \n",
    "- Alternatively, within Julia you can add workers by \n",
    "```julia\n",
    "using Distributed\n",
    "addprocs(4)  # add 4 worker processes\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The most straightforward way of performing distributed computing is using  `pmap`. \n",
    "- A good tutorial on how to use `pmap` can be found [here](https://github.com/Arpeggeo/julia-distributed-computing).\n",
    "- [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl) may be useful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "#### `MPI.jl`\n",
    "There exists an MPI (Message Passing Interface) interface for the Julia language, provided by the `MPI.jl` package. MPI is a low-level communication protocol that enables message passing between processes running on different nodes in a distributed system. It may be a better choice due to its interoperability, customization options, performance, and scalability on large-scale systems. If you never heard of it, then forget about it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## GPU computing\n",
    "\n",
    "Multiple dispatch allows your code to be executed on GPUS! Here is how.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.015 ms (4 allocations: 7.63 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6656771f8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reference function\n",
    "function myfun(a::AbstractArray, b::AbstractArray)\n",
    "    return sum(a.^2 * b)\n",
    "end\n",
    "\n",
    "# generate CPU arrays\n",
    "a = rand(Float32, 1000, 1000)\n",
    "b = rand(Float32, 1000, 1000)\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime myfun($a, $b) #  4.015 ms (4 allocations: 7.63 MiB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GPU programming with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "AssertionError: CUDA.functional()",
     "output_type": "error",
     "traceback": [
      "AssertionError: CUDA.functional()\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Academia/Postdoc_S2z/teaching/iDiv_Julia_workshop/materials/Day2/13_parallel_computing/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X46sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "@assert CUDA.functional()\n",
    "\n",
    "for d in devices()\n",
    "    println(d)\n",
    "end\n",
    "CUDA.device!(1)\n",
    "CUDA.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "CUDA driver not found",
     "output_type": "error",
     "traceback": [
      "CUDA driver not found\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base ./error.jl:35\n",
      " [2] functional\n",
      "   @ ~/.julia/packages/CUDA/Tl08O/src/initialization.jl:24 [inlined]\n",
      " [3] task_local_state!()\n",
      "   @ CUDA ~/.julia/packages/CUDA/Tl08O/lib/cudadrv/state.jl:77\n",
      " [4] active_state\n",
      "   @ ~/.julia/packages/CUDA/Tl08O/lib/cudadrv/state.jl:110 [inlined]\n",
      " [5] default_rng()\n",
      "   @ CUDA.CURAND ~/.julia/packages/CUDA/Tl08O/lib/curand/CURAND.jl:41\n",
      " [6] curand_rng\n",
      "   @ ~/.julia/packages/CUDA/Tl08O/src/random.jl:282 [inlined]\n",
      " [7] rand(dim1::Int64, dims::Int64)\n",
      "   @ CUDA ~/.julia/packages/CUDA/Tl08O/src/random.jl:336\n",
      " [8] top-level scope\n",
      "   @ ~/Academia/Postdoc_S2z/teaching/iDiv_Julia_workshop/materials/Day2/13_parallel_computing/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X50sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "a_cuda = CUDA.rand(1000, 1000)\n",
    "b_cuda = CUDA.rand(1000, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `a_cuda` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `a_cuda` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:496"
     ]
    }
   ],
   "source": [
    "@btime myfun($a_cuda, $b_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### GPU programming with Metal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.254 ms (892 allocations: 25.27 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6690597f8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Metal\n",
    "a_mtl = MtlArray(a)\n",
    "b_mtl = MtlArray(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@btime myfun($a_mtl, $b_mtl) # 1.254 ms (892 allocations: 25.27 KiB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Additional resources and acknowledgements\n",
    "- [Discourse category :Julia at scale](https://discourse.julialang.org/c/domain/parallel/34)\n",
    "- [Further explanations on Multithreading vs Multiprocessing computing](https://towardsdatascience.com/multithreading-and-multiprocessing-in-10-minutes-20d9b3c6a867)\n",
    "- [Julia multi threading](https://docs.julialang.org/en/v1/manual/multi-threading/)\n",
    "- [CUDA.jl documentation](https://github.com/JuliaGPU/CUDA.jl)\n",
    "- [A tutorial for using MPI.jl in ML](https://github.com/LuxDL/Lux.jl/tree/main/examples/ImageNet)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
