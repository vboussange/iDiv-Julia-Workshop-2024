{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A primer on mechanistic inference with differentiable process-based models in Julia\n\nHere you will learn about different techniques to infer parameters of a (differentiable) process-based model against data. This is useful to in the context of mechanistic inference, where we want to explain patterns in a system by understanding the processes that generate them, in contrast to purely statistical or empirical inference, which might identify patterns or correlations in data without necessarily understanding the causes. We'll mostly focus on differential equation models. Make sure that you stick to the end, where we'll see how we can not only infer parameter values but also functional forms, by parametrizing models' components with neural networks.\n\n- [A primer on mechanistic inference with differentiable process-based models in Julia](#a-primer-on-mechanistic-inference-with-differentiable-process-based-models-in-julia)\n  - [Wait, what is a differentiable model?](#wait-what-is-a-differentiable-model)\n  - [On the importance of gradients for inference](#on-the-importance-of-gradients-for-inference)\n  - [Automatic differentiation](#automatic-differentiation)\n  - [Lotka-Volterra equations](#lotka-volterra-equations)\n  - [Machine learning approach](#machine-learning-approach)\n    - [Exercise: Hey, this is cheating!](#exercise-hey-this-is-cheating)\n  - [Sensitivity methods](#sensitivity-methods)\n  - [Turing: Bayesian inference](#turing-bayesian-inference)\n    - [Our first Turing model](#our-first-turing-model)\n    - [Data retrodiction](#data-retrodiction)\n    - [Exercise: Hey, this is cheating!](#exercise-hey-this-is-cheating-1)\n    - [Mode estimation](#mode-estimation)\n    - [Partially observed state](#partially-observed-state)\n    - [AD backends and `sensealg`](#ad-backends-and-sensealg)\n    - [Using Variational Inference](#using-variational-inference)\n    - [Summary of resources Resources](#summary-of-resources-resources)\n\n\n## Wait, what is a differentiable model?\nOne can usually write a model as a map $\\mathcal{M}$ that maps some parameters $p$, an initial state $u_0$ and a time $t$ to a future state $u_t$\n\n$$u_t = \\mathcal{M}(u_0, t, p).$$\n\nWe call differentiable a model $\\mathcal{M}$ for which we can calculate its derivative with respect to $p$ or $u_0$. The derivative $\\frac{\\partial \\mathcal{M}}{\\partial \\theta}$ expresses how much the model output changes with respect to a small change in $\\theta$.\n\n$$f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n\nLet's illustrate this concept with the [logistic equation model](https://www.google.com/search?client=safari&rls=en&q=verhulst+equation&ie=UTF-8&oe=UTF-8).\n\nConsider the logistic growth model, which has an analytic solution given by:\n\n$\\mathcal{M}(u_0, p, t) = \\frac{u_0}{\\exp(-r \\cdot (t - t_0)) + b \\cdot u_0 \\cdot (1 - \\exp(-r \\cdot (t - t_0)))}\n$\n\nLet's code it"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using UnPack\nusing Plots\nusing Random\nusing ComponentArrays\nusing BenchmarkTools\nRandom.seed!(0)\n\nfunction mymodel(u0, p, t)\n    T = eltype(u0)\n    @unpack r, b = p\n    t0 = 0.\n\n    @. u0 / (exp(-r * (t - t0)) + b * u0 * (one(T) - exp(-r * (t - t0))))\nend\n\np = ComponentArray(;r = rand(), b = rand())\nu0 = rand()\n\ntsteps = range(0, 30, length=100)\ny = mymodel(u0, p, tsteps)\n\nplot(tsteps, y)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "!!! note \n    what is a `ComponentArray`?\n    A `ComponentArray` is a convenient Array type that allows to access array elements with symbols, similarly to a `NamedTuple`, while behaving like a standard array. For instance, you could do something like"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cv = ComponentVector(;a = 1, b = 2)\ncv .= [3, 4]"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is useful, because you cannot take a gradient w.r.t a `NamedTuple`, but you can with a `Vector`!\n\nNow let's try to calculate the gradient of this model. While you could in this case derive the gradient analytically, an analytic derivation is generally tricky with complex models. And what about models that can only be simulated numerically, with no analytic expressions? We need to find a more automatized way to calculate gradients. \n\nHow about [the finite difference method](https://en.wikipedia.org/wiki/Finite_difference_method)?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function ∂mymodel_∂p(h, u0, p, t)\n    phat = (; r = p.r, b= p.b + h)\n    return (mymodel(u0, phat, t) - mymodel(u0, p, t)) / h\nend\n\n∂mymodel_∂p(1e-1, u0, p, 1.)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gradient of the model is useful to understand how a parameter influences the output of the model. Let's calculate the important of the carrying capacity `b` on the model output:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "dm_dp = ∂mymodel_∂p(1e-1, u0, p, tsteps)\nplot(tsteps, dm_dp)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can observe, the carrying capacity has no effect at small $t$ where population is small, and its influence on the dynamics grows as the population grows. We expect the reverse effect for $r$.\n\n## On the importance of gradients for inference\n\nThe ability to calculate the derivative of a model is crucial when it comes to inference. Both within a full Bayesian inference context, where one wants to calculate the posterior distribution of parameters $\\theta$ given data $u$, $p(\\theta| u)$, or when one wants to obtain a point estimate $\\theta^\\star = \\argmax_\\theta (p(\\theta | u))$, this quantity is required.\n\nGiven an intial estimate, this gradient is used to suggest a new, better estimate.\n\n![](https://editor.analyticsvidhya.com/uploads/631731_P7z2BKhd0R-9uyn9ThDasA.png)\n\nGradient-based methods are usually very efficient in high-dimensional spaces. This is true in a Bayesian inference context with Hamiltonian Markov Chains, such as the NUTS sampler, or in a frequentist or machine learning, with gradient-based optimizer.\n\n## Automatic differentiation\n\nBut how do we choose `h` to calculate the derivative? This is a tricky question, because a too small `h` can lead to round off errors ([see more explanations here](https://book.sciml.ai/notes/08-Forward-Mode_Automatic_Differentiation_(AD)_via_High_Dimensional_Algebras/)) while `h` too large also leads to a bad approximation of the asymptotic definition.\n\nAlso, can you calculate how many evaluations of the model do you need if your parameter is $d$ dimensionsal?\n\n$\\mathcal{O}(2 d)$\n\nFortunately, Julia is an *AD-pervasive language*! This means that you can **exactly** differentiate any piece of function written in Julia, at low cost."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using ForwardDiff\n\n@btime ForwardDiff.gradient(p -> mymodel(u0, p, 1.), p)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what makes Julia great for model calibration and inference! Write your model in Julia, and any inference method using AD will be able to work with your model! This is not the case in Python or R, where you need to write your model in a machine learning framework such as Torch, JAX or Tensorflow, because those libraries do not know how to differentiate code not written in their own language.\n\nTo learn more about AD in Julia, check-out this [cool blog-post](https://gdalle.github.io/AutodiffTutorial/) and [a short presentation](https://gdalle.github.io/JuliaCon2024-AutoDiff/#/title-slide).\n\nNow let's get started with inference.\n\n\n## Lotka-Volterra equations\n\nWe'll use a simple dynamical community model, the [Lotka Volterra](https://en.wikipedia.org/wiki/Lotka–Volterra_equations) model, to generate the data. We'll then contaminate this data with noise, and assume that we do not know the exact parameters that have generated this data. \n\nThe goal of the session will be to estimate those parameters from the data, using a bunch of different techniques. \n\nSo let's first generate the data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using OrdinaryDiffEq\n\n# Define Lotka-Volterra model.\nfunction lotka_volterra(du, u, p, t)\n    # Model parameters.\n    @unpack α, β, γ, δ = p\n    # Current state.\n    x, y = u\n\n    # Evaluate differential equations.\n    du[1] = (α - β * y) * x # prey\n    du[2] = (δ * x - γ) * y # predator\n\n    return nothing\nend\n\n# Define initial-value problem.\nu0 = [2.0, 2.0]\np_true = (;α = 1.5, β = 1.0, γ = 3.0, δ = 1.0)\n# tspan = (hudson_bay_data[1,:t], hudson_bay_data[end,:t])\ntspan = (0., 5.)\nsaveat = 0.1\nalg = Tsit5()\n\nprob = ODEProblem(lotka_volterra, u0, tspan, p_true)\n\nsol_true = solve(prob, alg; saveat)\n# Plot simulation.\nplot(sol_true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the true state of the system. Now let's contaminate it with observational noise. We'll add lognormally distributed noise, because we are observing population abundance which can only be positive."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "data_mat = Array(sol_true) .* exp.(0.3 * randn(size(sol_true)))\n# Plot simulation and noisy observations.\nplot(sol_true; alpha=0.3)\nscatter!(sol_true.t, data_mat'; color=[1 2], label=\"\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our data, let's do some inference!\n\n\n## Machine learning approach\nWe'll get started with a very crude approach to inference, where we'll treat the calibration of our LV model similarly to a supervised machine learning task. To do so, we'll define a loss function, defining a distance between our model and the data, and we'll try to minimize this loss."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function loss(p)\n    predicted = solve(prob,\n                        alg; \n                        p, \n                        saveat,\n                        abstol=1e-6, \n                        reltol = 1e-6)\n\n    l = 0.\n    for i in 1:length(predicted)\n        if all(predicted[i] .> 0)\n            l += sum(abs2, log.(data_mat[:, i]) - log.(predicted[i]))\n        end\n    end\n\n    return l, predicted\n\n\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll define an initial estimate for the parameters, and we'll use a gradient-based optimizer that will iteratively update the parameters so as to minimize the loss, following a gradient descent approach\n\n$$\\theta_n = \\theta_{n-1} + \\eta \\nabla L(\\theta_n)$$\n\nWhere $\\eta$ is the learning rate.\n\nLet's define a helper function, that will plot how good does the model perform across different iterations."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "losses = []\ncallback = function (p, l, pred; doplot=true)\n    push!(losses, l)\n    if length(losses)%10==0\n      println(\"Current loss after $(length(losses)) iterations: $(losses[end])\")\n    end\n    if doplot\n        plt = scatter(sol_true.t, data_mat[1,:]; label = \"data x\", color = :blue, markerstrokewidth=0)\n        scatter!(plt, sol_true.t, Array(pred)[1,:]; label = \"prediction x\", color = :blue, markershape=:star5, markerstrokewidth=0)\n        scatter!(plt, sol_true.t, data_mat[2,:]; label = \"data y\", color = :red, markerstrokewidth=0)\n        scatter!(plt, sol_true.t, Array(pred)[2,:]; label = \"prediction y\", color = :red, markershape=:star5, markerstrokewidth=0)\n\n        display(plot(plt, yaxis = :log10))\n    end\n    return false\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's define a wrong initial guess"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "pinit = ComponentArray(;α = 1., β = 1.5, γ = 1.0, δ = 0.5)\n\ncallback(pinit, loss(pinit)...; doplot = true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's bad but that's what we want!\n\nWe'll use the library `Optimization` which is a wrapper library around many optimization libraries in Julia, providing you with many different types of optimizers. We'll use the infamous [ADAM optimizer](https://arxiv.org/abs/1412.6980) (187k citations!!!), widely used in ML."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Optimization\nusing OptimizationOptimisers\nusing SciMLSensitivity\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, pinit)\n\n@time res_ada = Optimization.solve(optprob, ADAGrad(0.1); callback = callback, maxiters = 500)\nres_ada.minimizer"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! It seems that the optimizer did a reasonable job, and that we found a reasonable estimate of our parameters!\n\n### Exercise: Hey, this is cheating!\n\nNotice that we use the true `u0`, as if we were to know exactly the initial state. In a real situation, we need also to infer the true state!\n\nCan you modify the model to infer the true state?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function loss2(p)\n    predicted = solve(prob,\n                        alg; \n                        p,\n                        u0 = p.u0,\n                        saveat,\n                        abstol=1e-6, \n                        reltol = 1e-6)\n\n    l = 0.\n    for i in 1:length(predicted)\n        if all(predicted[i] .> 0)\n            l += sum(abs2, log.(data_mat[:, i]) - log.(predicted[i]))\n        end\n    end\n    return l, predicted\nend\nlosses = []\n\npinit = ComponentArray(;α = 1., β = 1.5, γ = 1.0, δ = 0.5, u0 = data_mat[:,1])\n\nadtype = Optimization.AutoZygote()\noptf = Optimization.OptimizationFunction((x, p) -> loss2(x), adtype)\noptprob = Optimization.OptimizationProblem(optf, pinit)\n\n@time res_ada = Optimization.solve(optprob, ADAGrad(0.1); callback = callback, maxiters = 1000)\nres_ada.minimizer"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity methods\nWhat's `SciMLSensitivity`? and `adtype = Optimization.AutoZygote()`? Well, AD comes in different flavours, with broadly two types of AD - forward mode and backward mode -, and a bunch of different implementations. You can specify which ones to use with `adtype`, see available options [here](https://docs.sciml.ai/Optimization/stable/API/ad/). But when it comes to differentiating the `solve` function, you want to use `AutoZygote()`, because when trying to differentiate `solve`, the `Zygote` a specific adjoint rule provided by the `SciMLSensitivity` package will be used. These adjoint rules can be specificed by the keyword `sensealg` when calling `solve` and are designed for best performance when differentiating numerical solutions to ODEs. There exist a lot of them (see a review [here](https://arxiv.org/abs/2406.09699)), and if `sensealg` is not provided, a smart polyalgorithm is going to pick up one for you.\n\nSee [here](https://docs.sciml.ai/SciMLSensitivity/stable/manual/differential_equation_sensitivities/) for how to choose an algorithm, and let's evaluate the performance of two here for the specificity of our problem"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Zygote\nfunction loss_sensealg(p, sensealg)\n    predicted = solve(prob,\n                        alg; \n                        sensealg,\n                        p,\n                        u0 = p.u0,\n                        saveat,\n                        abstol=1e-6, \n                        reltol = 1e-6)\n\n    l = 0.\n    for i in 1:length(predicted)\n        if all(predicted[i] .> 0)\n            l += sum(abs2, log.(data_mat[:, i]) - log.(predicted[i]))\n        end\n    end\n    return l\nend\n\n@btime Zygote.gradient(p -> loss_sensealg(p, ForwardDiffSensitivity()), pinit)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@btime Zygote.gradient(p -> loss_sensealg(p, ReverseDiffAdjoint()), pinit)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a small number of parameters, forward methods tend to perform best, but with higher number of parameters, the other way around is true.\n\n\n## Turing: Bayesian inference\n\nWe'll first start by using the gold standard for inference: Bayesian inference. Julia has a very strong library for Bayesian inference: [Turing.jl](https://turinglang.org).\n\nLet's declare our first Turing model!\n\nTuring makes heavy use of macros, which allows the library to automatically construct the posterior distribution. Essentially, when defining a model, you need to append the macro `@model`, which will permit Turing.jl to adequately treat the random variables, defined with the `~` symbol.\n\n\n### Our first Turing model"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Turing\nusing LinearAlgebra\n\n# data_mat = hudson_bay_data[:, [:hare, :lynx]] |> Matrix\n\n@model function fitlv(data, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(3, 0.5)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n\n    # Simulate Lotka-Volterra model. \n    p = (;α, β, γ, δ)\n    predicted = solve(prob, alg; p, saveat)\n\n    # Observations.\n    for i in 1:length(predicted)\n        if all(predicted[i] .> 0)\n            data[:, i] ~ MvLogNormal(log.(predicted[i]), σ^2 * I)\n        end\n    end\n\n    return nothing\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can instantiate our model, and run the inference!"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "model = fitlv(data_mat, prob)\n\n# Sample 3 independent chains with forward-mode automatic differentiation (the default).\nchain = sample(model, NUTS(), MCMCThreads(), 1000, 3; progress=true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ! Threads\n> How many threads do you have running? `Threads.nthreads()` will tell you!\n\nLet's see if our chains have converged."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using StatsPlots\nplot(chain)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data retrodiction\n\nLet's now generate simulated data using samples from the posterior distribution, and compare to the original data."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function plot_predictions(chain, sol, data_mat)\n    myplot = plot(; legend=false)\n    posterior_samples = sample(chain[[:α, :β, :γ, :δ]], 300; replace=false)\n    for parr in eachrow(Array(posterior_samples))\n        p = NamedTuple([:α, :β, :γ, :δ] .=> parr)\n        sol_p = solve(prob, Tsit5(); p, saveat)\n        plot!(sol_p; alpha=0.1, color=\"#BBBBBB\")\n    end\n\n    # Plot simulation and noisy observations.\n    plot!(sol; color=[1 2], linewidth=1)\n    scatter!(sol.t, data_mat'; color=[1 2])\n    return myplot\nend\nplot_predictions(chain, sol_true, data_mat)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Hey, this is cheating!\n\nNotice that we use the true `u0`, as if we were to know exactly the initial state. In a real situation, we need also to infer the true state!\n\nCan you modify the model to infer the true state?"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function fitlv2(data, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(2, 3)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n    u0 ~ MvLogNormal(data[:,1], σ^2 * I)\n\n    # Simulate Lotka-Volterra model but save only the second state of the system (predators).\n    p = (;α, β, γ, δ)\n    predicted = solve(prob, alg; p, u0, saveat)\n\n    # Observations.\n    for i in 2:length(predicted)\n        if all(predicted[i] .> 0)\n            data[:, i] ~ MvLogNormal(log.(predicted[i]), σ^2 * I)\n        end\n    end\n\n    return nothing\n\nend\n\nmodel2 = fitlv2(data_mat, prob)\n\n# Sample 3 independent chains.\nchain2 = sample(model2, NUTS(), MCMCThreads(), 3000, 3; progress=true)\nplot(chain2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a small utility function to visualize your results."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function plot_predictions2(chain, sol, data_mat)\n    myplot = plot(; legend=false)\n    posterior_samples = sample(chain, 300; replace=false)\n    for i in 1:length(posterior_samples)\n        ps = posterior_samples[i]\n        p = get(ps, [:α, :β, :γ, :δ], flatten=true)\n        u0 = get(ps, :u0, flatten = true)\n        u0 = [u0[1][1], u0[2][1]]\n\n        sol_p = solve(prob, Tsit5(); u0, p, saveat)\n        plot!(sol_p; alpha=0.1, color=\"#BBBBBB\")\n    end\n\n    # Plot simulation and noisy observations.\n    plot!(sol; color=[1 2], linewidth=1)\n    scatter!(sol.t, data_mat'; color=[1 2])\n    return myplot\nend\n\nplot_predictions2(chain2, sol_true, data_mat)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mode estimation\nTuring allows you to find the maximum likelihood estimate (MLE) or maximum a posteriori estimate (MAP), similarly to what we have done by hand with the Optimization.jl library. These can be obtained by `maximum_likelihood` and `maximum_a_posteriori`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "Random.seed!(0)\nmaximum_a_posteriori(model2, maxiters = 1000)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since `Turing` uses under the hood the same Optimization.jl library, you can specify which optimizer youd'd like to use."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "map_res = maximum_a_posteriori(model2, Adam(0.01), maxiters=2000)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check whether the optimization has converged:"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@show map_res.optim_result"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's very nice is that Turing.jl provides you with utility functions to analyse your mode estimation results."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using StatsBase\ncoeftable(map_res)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partially observed state\nLet's assume an ever more complicated situation: for some reason, you only have observation data for the predator. Could you still infer all parameters of your model, including those of the prey?\n\nYES! Because the signal of the variation in abundance of the predator contains information on the dynamics of the whole predator-prey system.\n\nLet's see how we can do that with Turing.jl. Here we need to assume so prior state for the prey. We'll just assume that it is the same as that of the predator."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@model function fitlv3(data::AbstractVector, prob)\n    # Prior distributions.\n    σ ~ InverseGamma(2, 3)\n    α ~ truncated(Normal(1.5, 0.5); lower=0.5, upper=2.5)\n    β ~ truncated(Normal(1.2, 0.5); lower=0, upper=2)\n    γ ~ truncated(Normal(3.0, 0.5); lower=1, upper=4)\n    δ ~ truncated(Normal(1.0, 0.5); lower=0, upper=2)\n    u0 ~ MvLogNormal([data[1], data[1]], σ^2 * I)\n\n    # Simulate Lotka-Volterra model but save only the second state of the system (predators).\n    p = (;α, β, γ, δ)\n    predicted = solve(prob, Tsit5(); p, u0, saveat, save_idxs=2)\n\n    # Observations of the predators.\n    for i in 2:length(predicted)\n        if predicted[i] > 0\n            data[i] ~ LogNormal(log.(predicted[i]), σ^2)\n        end\n    end\n\n    return nothing\nend\n\nmodel3 = fitlv3(data_mat[2, :], prob)\n\n# Sample 3 independent chains.\nchain3 = sample(model3, NUTS(), MCMCThreads(), 3000, 3; progress=true)\nplot(chain3)\np = plot_predictions2(chain3, sol, data_mat)\nplot!(p, yaxis=:log10)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "How cool!\n\nNow you need to realise that up to now, we had a relatively simple model. How would this model scale, should we have a much larger model? Let's cook-up some idealised LV model.\n\n\n### AD backends and `sensealg`\nThe `NUTS` sampler uses automatic differentiation under the hood. \n\nBy default, `Turing.jl` uses `ForwardDiff.jl` as an AD backend, meaning that the SciML sensitivity methods are not used when the `solve` function is called. However, you could change the AD backend to `Zygote` with `adtype=AutoZygote()`."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "chain2 = sample(model2, NUTS(), MCMCThreads(), adtype=AutoZygote(), 3000, 3; progress=true)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "See [here](https://turinglang.org/docs/tutorials/docs-10-using-turing-autodiff/index.html) for more information. \n\n### Using Variational Inference"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "import Flux\nusing Turing: Variational\nmodel = fitlv2(data_mat, prob)\nq0 = Variational.meanfield(model)\nadvi = ADVI(10, 10_000)\n\nq = vi(model, advi, q0; optimizer=Flux.ADAM(1e-2))\n\nfunction plot_predictions_vi(q, sol, data_mat)\n    myplot = plot(; legend=false)\n    z = rand(q, 300)\n    for parr in eachcol(z)\n        p = NamedTuple([:α, :β, :γ, :δ] .=> parr[2:5])\n        u0 = parr[6:7]\n        sol_p = solve(prob, Tsit5(); u0, p, saveat)\n        plot!(sol_p; alpha=0.1, color=\"#BBBBBB\")\n    end\n\n    # Plot simulation and noisy observations.\n    plot!(sol; color=[1 2], linewidth=1)\n    scatter!(sol.t, data_mat'; color=[1 2])\n    return myplot\nend\n\nplot_predictions_vi(q, sol, data_mat)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://turinglang.org/docs/tutorials/09-variational-inference/\n\n### Summary of resources Resources\n- https://turinglang.org/docs/tutorials/10-bayesian-differential-equations/\n- https://turinglang.org/docs/tutorials/09-variational-inference/"
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.10.2"
    },
    "kernelspec": {
      "name": "julia-1.10",
      "display_name": "Julia 1.10.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
